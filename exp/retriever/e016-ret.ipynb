{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71acc131",
   "metadata": {
    "papermill": {
     "duration": 0.011532,
     "end_time": "2024-09-14T01:45:57.074016",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.062484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 目的\n",
    "stella_en_1.5B_v5をfine-tuningする\n",
    "\n",
    "ref: https://sbert.net/docs/sentence_transformer/training_overview.html#trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c5e900",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:22.755166Z",
     "iopub.status.busy": "2024-11-04T08:57:22.754707Z",
     "iopub.status.idle": "2024-11-04T08:57:23.100071Z",
     "shell.execute_reply": "2024-11-04T08:57:23.098068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  4 09:19:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:01:00.0 Off |                  Off |\n",
      "| 32%   39C    P8              19W / 300W |  48658MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc8a91",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c063a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:23.105430Z",
     "iopub.status.busy": "2024-11-04T08:57:23.104944Z",
     "iopub.status.idle": "2024-11-04T08:57:23.114942Z",
     "shell.execute_reply": "2024-11-04T08:57:23.113823Z"
    }
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"e016-ret-stella\"\n",
    "DATA_PATH = \"data\"\n",
    "MODEL_NAME = \"dunzhang/stella_en_1.5B_v5\"\n",
    "ENV_PATH = \"env_file\"\n",
    "COMPETITION_NAME = \"eedi-mining-misconceptions-in-mathematics\"\n",
    "RETRIVED_FILE_PATH = (\n",
    "    \"output/retriever/e003-ret-bge/e003-ret-bge-ret25-map0.1841-recall0.5506.csv\"\n",
    ")\n",
    "\n",
    "# RETRIVED_EX_FILE_PATH = \"output/retriever/e013-ret-bge-prepare/e013-ret-bge-prepare-ret25-map0.4374-recall0.8410.csv\"\n",
    "\n",
    "DATASET_NAME = EXP_NAME\n",
    "OUTPUT_PATH = f\"output/retriever/{EXP_NAME}\"\n",
    "# MODEL_OUTPUT_PATH = f\"{OUTPUT_PATH}/trained_model\"\n",
    "MODEL_OUTPUT_PATH = f\"{OUTPUT_PATH}/checkpoint-5010\"\n",
    "\n",
    "TRAIN_USE_NUM = 5\n",
    "RETRIEVE_NUM = 25  # TODO: 多くしてみる\n",
    "\n",
    "EPOCH = 5\n",
    "BS = 1  # 2  # 4  # 8\n",
    "GRAD_ACC_STEP = 1  # bugがあるので1にする。# 128 // BS\n",
    "LR = 2e-5\n",
    "\n",
    "TRAINING = True\n",
    "DEBUG = False\n",
    "WANDB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d2d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:23.119381Z",
     "iopub.status.busy": "2024-11-04T08:57:23.118824Z",
     "iopub.status.idle": "2024-11-04T08:57:23.129894Z",
     "shell.execute_reply": "2024-11-04T08:57:23.129320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/eedi-mining-misconceptions-in-mathematics/exp/retriever\n",
      "VastAi! Retriever\n",
      "../../data\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/retriever\n",
      "VastAi! Retriever\n",
      "../../output/retriever/e016-ret-stella\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/retriever\n",
      "VastAi! Retriever\n",
      "../../output/retriever/e016-ret-stella/checkpoint-5010\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/retriever\n",
      "VastAi! Retriever\n",
      "../../env_file\n",
      "/root/eedi-mining-misconceptions-in-mathematics/exp/retriever\n",
      "VastAi! Retriever\n",
      "../../output/retriever/e003-ret-bge/e003-ret-bge-ret25-map0.1841-recall0.5506.csv\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}/exp/reranker\":\n",
    "        print(\"VastAi! Reranker\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}/exp/retriever\":\n",
    "        print(\"VastAi! Retriever\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd == f\"/root/{COMPETITION_NAME}\":\n",
    "        print(\"VastAi!\")\n",
    "        return base_path\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "OUTPUT_PATH = resolve_path(OUTPUT_PATH)\n",
    "print(OUTPUT_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)\n",
    "ENV_PATH = resolve_path(ENV_PATH)\n",
    "print(ENV_PATH)\n",
    "RETRIVED_FILE_PATH = resolve_path(RETRIVED_FILE_PATH)\n",
    "print(RETRIVED_FILE_PATH)\n",
    "# RETRIVED_EX_FILE_PATH = resolve_path(RETRIVED_EX_FILE_PATH)\n",
    "# print(RETRIVED_EX_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e26266",
   "metadata": {
    "papermill": {
     "duration": 0.010544,
     "end_time": "2024-09-14T01:45:57.095623",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.085079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c0dbcc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:23.132281Z",
     "iopub.status.busy": "2024-11-04T08:57:23.131935Z",
     "iopub.status.idle": "2024-11-04T08:57:24.913518Z",
     "shell.execute_reply": "2024-11-04T08:57:24.913150Z"
    },
    "papermill": {
     "duration": 2.430721,
     "end_time": "2024-09-14T01:45:59.537229",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.106508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import wandb\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc40cda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:24.915078Z",
     "iopub.status.busy": "2024-11-04T08:57:24.914894Z",
     "iopub.status.idle": "2024-11-04T08:57:24.916834Z",
     "shell.execute_reply": "2024-11-04T08:57:24.916610Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sentence_transformers\n",
    "\n",
    "assert transformers.__version__ == \"4.44.2\"\n",
    "assert sentence_transformers.__version__ == \"3.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d1b181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:24.917981Z",
     "iopub.status.busy": "2024-11-04T08:57:24.917887Z",
     "iopub.status.idle": "2024-11-04T08:57:24.919556Z",
     "shell.execute_reply": "2024-11-04T08:57:24.919335Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_PROC = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85aefdc",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896ee0be",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:24.920709Z",
     "iopub.status.busy": "2024-11-04T08:57:24.920602Z",
     "iopub.status.idle": "2024-11-04T08:57:24.925768Z",
     "shell.execute_reply": "2024-11-04T08:57:24.925548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{ENV_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb645be4",
   "metadata": {},
   "source": [
    "# WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7360a36",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:24.926995Z",
     "iopub.status.busy": "2024-11-04T08:57:24.926863Z",
     "iopub.status.idle": "2024-11-04T08:57:25.964125Z",
     "shell.execute_reply": "2024-11-04T08:57:25.963801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/eedi-mining-misconceptions-in-mathematics/exp/retriever/wandb/run-20241104_091957-ecfgyib1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/ecfgyib1' target=\"_blank\">e016-ret-stella</a></strong> to <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/ecfgyib1' target=\"_blank\">https://wandb.ai/sinchir0/eedi-mining-misconceptions-in-mathematics/runs/ecfgyib1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98570c57",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7320b8",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:25.965216Z",
     "iopub.status.busy": "2024-11-04T08:57:25.965127Z",
     "iopub.status.idle": "2024-11-04T08:57:27.279128Z",
     "shell.execute_reply": "2024-11-04T08:57:27.278560Z"
    }
   },
   "outputs": [],
   "source": [
    "train = (\n",
    "    load_dataset(\n",
    "        \"csv\",\n",
    "        data_files=RETRIVED_FILE_PATH,\n",
    "        split=\"train\",\n",
    "    )\n",
    "    .filter(\n",
    "        lambda example: example[\"MisconceptionId\"] is not None,\n",
    "        num_proc=NUM_PROC,\n",
    "    )\n",
    "    .filter(  # anchor、positive、negativeの構成にするため、positiveとnegativeが一致している行を削除する\n",
    "        lambda example: example[\"MisconceptionId\"] != example[\"PredictMisconceptionId\"],\n",
    "        num_proc=NUM_PROC,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626b8229",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.281007Z",
     "iopub.status.busy": "2024-11-04T08:57:27.280856Z",
     "iopub.status.idle": "2024-11-04T08:57:27.283736Z",
     "shell.execute_reply": "2024-11-04T08:57:27.283517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AllText', 'AnswerAlphabet', 'QuestionId_Answer', 'MisconceptionId', 'PredictMisconceptionId', 'target', 'MisconceptionName', 'PredictMisconceptionName'],\n",
       "    num_rows: 106844\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a95079c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.284995Z",
     "iopub.status.busy": "2024-11-04T08:57:27.284881Z",
     "iopub.status.idle": "2024-11-04T08:57:27.286441Z",
     "shell.execute_reply": "2024-11-04T08:57:27.286218Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 同じMisconceptionNameのpositiveの例を25個→5個に減らす\n",
    "# train = Dataset.from_pandas(\n",
    "#     train.to_pandas().groupby(\"QuestionId_Answer\").head(TRAIN_USE_NUM)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc872920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.287717Z",
     "iopub.status.busy": "2024-11-04T08:57:27.287578Z",
     "iopub.status.idle": "2024-11-04T08:57:27.289208Z",
     "shell.execute_reply": "2024-11-04T08:57:27.288956Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fafd4a3",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.290450Z",
     "iopub.status.busy": "2024-11-04T08:57:27.290293Z",
     "iopub.status.idle": "2024-11-04T08:57:27.595637Z",
     "shell.execute_reply": "2024-11-04T08:57:27.595127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the order of operations to carry out calculations involving powers BIDMAS \\[\n",
      "3 \\times 2+4-5\n",
      "\\]\n",
      "Where do the brackets need to go to make the answer equal \\( 13 \\) ? Does not need brackets\n"
     ]
    }
   ],
   "source": [
    "print(train[\"AllText\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c762b2",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.596812Z",
     "iopub.status.busy": "2024-11-04T08:57:27.596715Z",
     "iopub.status.idle": "2024-11-04T08:57:27.869902Z",
     "shell.execute_reply": "2024-11-04T08:57:27.869517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confuses the order of operations, believes addition comes before multiplication \n"
     ]
    }
   ],
   "source": [
    "print(train[\"MisconceptionName\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9db6787d",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:27.871029Z",
     "iopub.status.busy": "2024-11-04T08:57:27.870921Z",
     "iopub.status.idle": "2024-11-04T08:57:28.069884Z",
     "shell.execute_reply": "2024-11-04T08:57:28.069614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies BIDMAS in strict order (does not realize addition and subtraction, and multiplication and division, are of equal priority)\n"
     ]
    }
   ],
   "source": [
    "print(train[\"PredictMisconceptionName\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89161999",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:28.071214Z",
     "iopub.status.busy": "2024-11-04T08:57:28.071079Z",
     "iopub.status.idle": "2024-11-04T08:57:28.072827Z",
     "shell.execute_reply": "2024-11-04T08:57:28.072604Z"
    }
   },
   "outputs": [],
   "source": [
    "# # load ex data\n",
    "# train_ex = (\n",
    "#     load_dataset(\n",
    "#         \"csv\",\n",
    "#         data_files=RETRIVED_EX_FILE_PATH,\n",
    "#         split=\"train\",\n",
    "#     )\n",
    "#     .filter(  # Nameを正しく生成できず、Idが紐づかなかったデータを落とす\n",
    "#         lambda example: example[\"MisconceptionId\"] is not None,\n",
    "#         num_proc=NUM_PROC,\n",
    "#     )\n",
    "#     .filter(  # anchor、positive、negativeの構成にするため、positiveとnegativeが一致している行を削除する\n",
    "#         lambda example: example[\"MisconceptionId\"] != example[\"PredictMisconceptionId\"],\n",
    "#         num_proc=NUM_PROC,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# train_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf26818",
   "metadata": {},
   "source": [
    "# Train Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dcb4968",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:28.074123Z",
     "iopub.status.busy": "2024-11-04T08:57:28.073924Z",
     "iopub.status.idle": "2024-11-04T08:57:29.189991Z",
     "shell.execute_reply": "2024-11-04T08:57:29.189296Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid = (\n",
    "    train.filter(lambda example: example[\"QuestionId\"] % 3 != 0, num_proc=NUM_PROC),\n",
    "    train.filter(lambda example: example[\"QuestionId\"] % 3 == 0, num_proc=NUM_PROC),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8184ebdf",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:29.192168Z",
     "iopub.status.busy": "2024-11-04T08:57:29.192033Z",
     "iopub.status.idle": "2024-11-04T08:57:29.195734Z",
     "shell.execute_reply": "2024-11-04T08:57:29.195088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AllText', 'AnswerAlphabet', 'QuestionId_Answer', 'MisconceptionId', 'PredictMisconceptionId', 'target', 'MisconceptionName', 'PredictMisconceptionName'],\n",
      "    num_rows: 71119\n",
      "})\n",
      "Dataset({\n",
      "    features: ['QuestionId', 'ConstructName', 'SubjectName', 'QuestionText', 'CorrectAnswer', 'AnswerType', 'AnswerText', 'AllText', 'AnswerAlphabet', 'QuestionId_Answer', 'MisconceptionId', 'PredictMisconceptionId', 'target', 'MisconceptionName', 'PredictMisconceptionName'],\n",
      "    num_rows: 35725\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0eeff4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:29.197693Z",
     "iopub.status.busy": "2024-11-04T08:57:29.197466Z",
     "iopub.status.idle": "2024-11-04T08:57:29.199897Z",
     "shell.execute_reply": "2024-11-04T08:57:29.199424Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "\n",
    "# train = concatenate_datasets([train, train_ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18dcd2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:29.202218Z",
     "iopub.status.busy": "2024-11-04T08:57:29.201951Z",
     "iopub.status.idle": "2024-11-04T08:57:29.204416Z",
     "shell.execute_reply": "2024-11-04T08:57:29.203866Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(train)\n",
    "# print(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d11def",
   "metadata": {
    "papermill": {
     "duration": 0.010829,
     "end_time": "2024-09-14T01:46:00.109663",
     "exception": false,
     "start_time": "2024-09-14T01:46:00.098834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ec1e23",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-04T08:57:29.206302Z",
     "iopub.status.busy": "2024-11-04T08:57:29.206084Z",
     "iopub.status.idle": "2024-11-04T09:04:58.765838Z",
     "shell.execute_reply": "2024-11-04T09:04:58.765234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25804dc1d87949848b490bfc6bf0563c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d913e75aa234dc3a6a5f1c7441cc97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb1abb0d6344d13aa67be6f2c04df9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/174k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926454dbe07e4d7fae6751ef8b1075cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d14f1865f644aab674903129242fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9f7a57e5f34f58acb149331d8df9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_qwen.py:   0%|          | 0.00/65.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAINING:\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m MultipleNegativesRankingLoss(model)\n\u001b[1;32m      6\u001b[0m     args \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainingArguments(\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# Required parameter:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_PATH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:294\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    285\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[1;32m    288\u001b[0m     model_name_or_path,\n\u001b[1;32m    289\u001b[0m     token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    293\u001b[0m ):\n\u001b[0;32m--> 294\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    307\u001b[0m         model_name_or_path,\n\u001b[1;32m    308\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    316\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1647\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1647\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(model_name_or_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:56\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     55\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[1;32m     59\u001b[0m     tokenizer_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_seq_length\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:87\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:551\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    550\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mauto_map[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 551\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m     _ \u001b[38;5;241m=\u001b[39m hub_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:502\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     code_revision \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m final_module \u001b[38;5;241m=\u001b[39m \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_class_in_module(class_name, final_module)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:327\u001b[0m, in \u001b[0;36mget_cached_module_file\u001b[0;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Check we have all the requirements in our environment\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m modules_needed \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_module_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m full_submodule \u001b[38;5;241m=\u001b[39m TRANSFORMERS_DYNAMIC_MODULE_NAME \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m+\u001b[39m submodule\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:182\u001b[0m, in \u001b[0;36mcheck_imports\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    179\u001b[0m         missing_packages\u001b[38;5;241m.\u001b[39mappend(imp)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_packages) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis modeling file requires the following packages that were not found in your environment: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Run `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_relative_imports(filename)\n",
      "\u001b[0;31mImportError\u001b[0m: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "    loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=OUTPUT_PATH,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=EPOCH,\n",
    "        per_device_train_batch_size=BS,  # 16,\n",
    "        gradient_accumulation_steps=GRAD_ACC_STEP,\n",
    "        per_device_eval_batch_size=BS,  # 16,\n",
    "        eval_accumulation_steps=GRAD_ACC_STEP,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        fp16_full_eval=True,\n",
    "        bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "        # Optional tracking/debugging parameters:\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        save_total_limit=2,\n",
    "        logging_steps=100,\n",
    "        report_to=REPORT_TO,  # Will be used in W&B if `wandb` is installed\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "    )\n",
    "\n",
    "    dev_evaluator = TripletEvaluator(\n",
    "        anchors=valid[\"AllText\"],\n",
    "        positives=valid[\"MisconceptionName\"],\n",
    "        negatives=valid[\"PredictMisconceptionName\"],\n",
    "        name=f\"{MODEL_NAME}-dev\",\n",
    "    )\n",
    "    # dev_evaluator(model)\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train.select_columns(\n",
    "            [\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]\n",
    "        ),\n",
    "        eval_dataset=valid.select_columns(\n",
    "            [\"AllText\", \"MisconceptionName\", \"PredictMisconceptionName\"]\n",
    "        ),\n",
    "        loss=loss,\n",
    "        evaluator=dev_evaluator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    model = SentenceTransformer(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5e067",
   "metadata": {},
   "source": [
    "# Make Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e617cb",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.202611Z",
     "iopub.status.busy": "2024-10-13T17:53:55.202065Z",
     "iopub.status.idle": "2024-10-13T17:53:55.229337Z",
     "shell.execute_reply": "2024-10-13T17:53:55.228568Z"
    }
   },
   "outputs": [],
   "source": [
    "common_col = [\n",
    "    \"QuestionId\",\n",
    "    \"ConstructName\",\n",
    "    \"SubjectName\",\n",
    "    \"QuestionText\",\n",
    "    \"CorrectAnswer\",\n",
    "]\n",
    "\n",
    "train_long = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .select(\n",
    "        pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n",
    "    )\n",
    "    .unpivot(\n",
    "        index=common_col,\n",
    "        variable_name=\"AnswerType\",\n",
    "        value_name=\"AnswerText\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col(\"ConstructName\"),\n",
    "                pl.col(\"SubjectName\"),\n",
    "                pl.col(\"QuestionText\"),\n",
    "                pl.col(\"AnswerText\"),\n",
    "            ],\n",
    "            separator=\" \",\n",
    "        ).alias(\"AllText\"),\n",
    "        pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n",
    "        ).alias(\"QuestionId_Answer\"),\n",
    "    )\n",
    "    .sort(\"QuestionId_Answer\")\n",
    ")\n",
    "train_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee44be4",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.233046Z",
     "iopub.status.busy": "2024-10-13T17:53:55.232751Z",
     "iopub.status.idle": "2024-10-13T17:53:55.247350Z",
     "shell.execute_reply": "2024-10-13T17:53:55.246649Z"
    }
   },
   "outputs": [],
   "source": [
    "train_misconception_long = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .select(\n",
    "        pl.col(\n",
    "            common_col + [f\"Misconception{alpha}Id\" for alpha in [\"A\", \"B\", \"C\", \"D\"]]\n",
    "        )\n",
    "    )\n",
    "    .unpivot(\n",
    "        index=common_col,\n",
    "        variable_name=\"MisconceptionType\",\n",
    "        value_name=\"MisconceptionId\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"MisconceptionType\")\n",
    "        .str.extract(r\"Misconception([A-D])Id$\")\n",
    "        .alias(\"AnswerAlphabet\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n",
    "        ).alias(\"QuestionId_Answer\"),\n",
    "    )\n",
    "    .sort(\"QuestionId_Answer\")\n",
    "    .select(pl.col([\"QuestionId_Answer\", \"MisconceptionId\"]))\n",
    "    .with_columns(pl.col(\"MisconceptionId\").cast(pl.Int64))\n",
    ")\n",
    "train_misconception_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d824b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.250433Z",
     "iopub.status.busy": "2024-10-13T17:53:55.250274Z",
     "iopub.status.idle": "2024-10-13T17:53:55.254341Z",
     "shell.execute_reply": "2024-10-13T17:53:55.253650Z"
    }
   },
   "outputs": [],
   "source": [
    "# join MisconceptionId\n",
    "train_long = train_long.join(train_misconception_long, on=\"QuestionId_Answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bad18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.258006Z",
     "iopub.status.busy": "2024-10-13T17:53:55.257661Z",
     "iopub.status.idle": "2024-10-13T17:53:55.405542Z",
     "shell.execute_reply": "2024-10-13T17:53:55.404616Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_long = train_long.filter(\n",
    "    pl.col(\"QuestionId_Answer\").is_in(set(valid[\"QuestionId_Answer\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22563ddd",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.409889Z",
     "iopub.status.busy": "2024-10-13T17:53:55.409275Z",
     "iopub.status.idle": "2024-10-13T17:53:55.415820Z",
     "shell.execute_reply": "2024-10-13T17:53:55.415125Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d8541",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:55.419988Z",
     "iopub.status.busy": "2024-10-13T17:53:55.419632Z",
     "iopub.status.idle": "2024-10-13T17:53:59.533832Z",
     "shell.execute_reply": "2024-10-13T17:53:59.532612Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(MODEL_OUTPUT_PATH)\n",
    "\n",
    "valid_long_vec = model.encode(\n",
    "    valid_long[\"AllText\"].to_list(), normalize_embeddings=True\n",
    ")\n",
    "misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")\n",
    "misconception_mapping_vec = model.encode(\n",
    "    misconception_mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True\n",
    ")\n",
    "print(valid_long_vec.shape)\n",
    "print(misconception_mapping_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368fe01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:59.537606Z",
     "iopub.status.busy": "2024-10-13T17:53:59.537376Z",
     "iopub.status.idle": "2024-10-13T17:53:59.546717Z",
     "shell.execute_reply": "2024-10-13T17:53:59.545898Z"
    }
   },
   "outputs": [],
   "source": [
    "# misconception_mapping_vecを保存する\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "np.save(f\"{OUTPUT_PATH}/misconception_mapping_vec.npy\", misconception_mapping_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171be61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:59.550365Z",
     "iopub.status.busy": "2024-10-13T17:53:59.549981Z",
     "iopub.status.idle": "2024-10-13T17:53:59.979226Z",
     "shell.execute_reply": "2024-10-13T17:53:59.978348Z"
    },
    "papermill": {
     "duration": 5.023799,
     "end_time": "2024-09-14T01:46:06.422421",
     "exception": false,
     "start_time": "2024-09-14T01:46:01.398622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_cos_sim_arr = cosine_similarity(valid_long_vec, misconception_mapping_vec)\n",
    "valid_sorted_indices = np.argsort(-valid_cos_sim_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288a590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:59.983340Z",
     "iopub.status.busy": "2024-10-13T17:53:59.983050Z",
     "iopub.status.idle": "2024-10-13T17:53:59.987232Z",
     "shell.execute_reply": "2024-10-13T17:53:59.986637Z"
    },
    "papermill": {
     "duration": 0.025202,
     "end_time": "2024-09-14T01:46:06.496371",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.471169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example\n",
    "def print_example(df: pl.DataFrame, sorted_indices: np.ndarray, idx: int) -> None:\n",
    "    print(f\"Query idx{idx}\")\n",
    "    print(df[\"AllText\"][idx])\n",
    "    print(\"\\nCos Sim No.1\")\n",
    "    print(misconception_mapping[\"MisconceptionName\"][int(sorted_indices[idx, 0])])\n",
    "    print(\"\\nCos Sim No.2\")\n",
    "    print(misconception_mapping[\"MisconceptionName\"][int(sorted_indices[idx, 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85607c",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:59.990711Z",
     "iopub.status.busy": "2024-10-13T17:53:59.990388Z",
     "iopub.status.idle": "2024-10-13T17:53:59.994817Z",
     "shell.execute_reply": "2024-10-13T17:53:59.994217Z"
    }
   },
   "outputs": [],
   "source": [
    "print_example(train_long, valid_sorted_indices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211ff44",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:53:59.998285Z",
     "iopub.status.busy": "2024-10-13T17:53:59.997924Z",
     "iopub.status.idle": "2024-10-13T17:54:00.001908Z",
     "shell.execute_reply": "2024-10-13T17:54:00.001312Z"
    },
    "papermill": {
     "duration": 0.022384,
     "end_time": "2024-09-14T01:46:06.530441",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.508057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_example(train_long, valid_sorted_indices, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe1e2c",
   "metadata": {
    "papermill": {
     "duration": 0.011086,
     "end_time": "2024-09-14T01:46:06.552908",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.541822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5f922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.005248Z",
     "iopub.status.busy": "2024-10-13T17:54:00.004916Z",
     "iopub.status.idle": "2024-10-13T17:54:00.024067Z",
     "shell.execute_reply": "2024-10-13T17:54:00.023456Z"
    },
    "papermill": {
     "duration": 0.04065,
     "end_time": "2024-09-14T01:46:06.605893",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.565243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_long = valid_long.with_columns(\n",
    "    pl.Series(valid_sorted_indices[:, :RETRIEVE_NUM].tolist()).alias(\n",
    "        \"PredictMisconceptionId\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b400a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.027577Z",
     "iopub.status.busy": "2024-10-13T17:54:00.027212Z",
     "iopub.status.idle": "2024-10-13T17:54:00.030942Z",
     "shell.execute_reply": "2024-10-13T17:54:00.030350Z"
    },
    "papermill": {
     "duration": 0.023321,
     "end_time": "2024-09-14T01:46:06.640719",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.617398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1#MAP@3-Metric\n",
    "def map_at_25(predictions, labels):\n",
    "    map_sum = 0\n",
    "    for x, y in zip(predictions, labels):\n",
    "        z = [1 / i if y == j else 0 for i, j in zip(range(1, 26), x)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd99f42",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.034316Z",
     "iopub.status.busy": "2024-10-13T17:54:00.034034Z",
     "iopub.status.idle": "2024-10-13T17:54:00.063176Z",
     "shell.execute_reply": "2024-10-13T17:54:00.062601Z"
    },
    "papermill": {
     "duration": 0.113621,
     "end_time": "2024-09-14T01:46:06.765721",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.652100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_at_25_score = map_at_25(\n",
    "    valid_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\n",
    "        \"PredictMisconceptionId\"\n",
    "    ],\n",
    "    valid_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\"MisconceptionId\"],\n",
    ")\n",
    "map_at_25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66afa0",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.066541Z",
     "iopub.status.busy": "2024-10-13T17:54:00.066180Z",
     "iopub.status.idle": "2024-10-13T17:54:00.217272Z",
     "shell.execute_reply": "2024-10-13T17:54:00.216574Z"
    },
    "papermill": {
     "duration": 0.034606,
     "end_time": "2024-09-14T01:46:06.812192",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.777586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall(predictions, labels):\n",
    "    acc_num = np.sum([1 for x, y in zip(predictions, labels) if y in x])\n",
    "    return acc_num / len(predictions)\n",
    "\n",
    "\n",
    "recall_score = recall(\n",
    "    valid_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\n",
    "        \"PredictMisconceptionId\"\n",
    "    ],\n",
    "    valid_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\"MisconceptionId\"],\n",
    ")\n",
    "recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0988734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.220749Z",
     "iopub.status.busy": "2024-10-13T17:54:00.220376Z",
     "iopub.status.idle": "2024-10-13T17:54:00.223789Z",
     "shell.execute_reply": "2024-10-13T17:54:00.223094Z"
    }
   },
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(f\"MAP@25:{map_at_25_score:.4f}, Recall:{recall_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657bf3d",
   "metadata": {
    "papermill": {
     "duration": 0.011875,
     "end_time": "2024-09-14T01:46:07.146569",
     "exception": false,
     "start_time": "2024-09-14T01:46:07.134694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Retrieved Train File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ca4b1",
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.227064Z",
     "iopub.status.busy": "2024-10-13T17:54:00.226744Z",
     "iopub.status.idle": "2024-10-13T17:54:00.237168Z",
     "shell.execute_reply": "2024-10-13T17:54:00.236462Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_retrieved = (\n",
    "    valid_long.filter(pl.col(\"MisconceptionId\").is_not_null())\n",
    "    .explode(\"PredictMisconceptionId\")\n",
    "    .with_columns(\n",
    "        (pl.col(\"MisconceptionId\") == pl.col(\"PredictMisconceptionId\"))\n",
    "        .cast(pl.Int64)\n",
    "        .alias(\"target\")\n",
    "    )\n",
    "    .join(\n",
    "        misconception_mapping.with_columns(pl.all().name.prefix(\"Predict\")),\n",
    "        on=\"PredictMisconceptionId\",\n",
    "    )\n",
    ")\n",
    "valid_retrieved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd7ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.240890Z",
     "iopub.status.busy": "2024-10-13T17:54:00.240326Z",
     "iopub.status.idle": "2024-10-13T17:54:00.262855Z",
     "shell.execute_reply": "2024-10-13T17:54:00.261970Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_retrieved.write_csv(\n",
    "    f\"{MODEL_OUTPUT_PATH}/{EXP_NAME}-valid-ret{RETRIEVE_NUM}-map{map_at_25_score:.4f}-recall{recall_score:.4f}.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d6dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.266236Z",
     "iopub.status.busy": "2024-10-13T17:54:00.265939Z",
     "iopub.status.idle": "2024-10-13T17:54:00.270059Z",
     "shell.execute_reply": "2024-10-13T17:54:00.269461Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{MODEL_OUTPUT_PATH}/{EXP_NAME}-valid-ret{RETRIEVE_NUM}-map{map_at_25_score:.4f}-recall{recall_score:.4f}.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa7596",
   "metadata": {},
   "source": [
    "# Kaggle Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368627a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T17:54:00.273197Z",
     "iopub.status.busy": "2024-10-13T17:54:00.273039Z",
     "iopub.status.idle": "2024-10-13T17:58:23.850447Z",
     "shell.execute_reply": "2024-10-13T17:58:23.848332Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    # if \"_\" in dataset_name:\n",
    "    #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "    dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "    dataset_metadata[\"title\"] = dataset_name\n",
    "    with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "\n",
    "print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{OUTPUT_PATH}\")\n",
    "dataset_create_new(dataset_name=DATASET_NAME, upload_dir=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20375e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9551816,
     "sourceId": 82695,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.614286,
   "end_time": "2024-09-14T01:46:08.075104",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-14T01:45:53.460818",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "25da2f78e964412589f99a1e4a645b67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "264822a703204dfc89d15253da32e2a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "32b1e04bd8604568a745f6cb757cb4ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be53d6809fd14c1299091d250745d4d4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5133d294d91f48909fa4c24e7df7f1bc",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "5133d294d91f48909fa4c24e7df7f1bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94da6364db30452f8b4991c203d8c94d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_99b6036e0c424a998c600443415bd61c",
        "IPY_MODEL_32b1e04bd8604568a745f6cb757cb4ca",
        "IPY_MODEL_9cec1df457744eed8dac667f438ee390"
       ],
       "layout": "IPY_MODEL_264822a703204dfc89d15253da32e2a2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "99b6036e0c424a998c600443415bd61c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7660448dc514841b062bd08d8f0233c",
       "placeholder": "​",
       "style": "IPY_MODEL_cd9fd81e133c4775bb6f66b326ecb6d7",
       "tabbable": null,
       "tooltip": null,
       "value": "Computing widget examples:   0%"
      }
     },
     "9cec1df457744eed8dac667f438ee390": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be3c8efcb7e54c84b5244c1763a4bf06",
       "placeholder": "​",
       "style": "IPY_MODEL_25da2f78e964412589f99a1e4a645b67",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/1 [00:00&lt;?, ?example/s]"
      }
     },
     "b7660448dc514841b062bd08d8f0233c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be3c8efcb7e54c84b5244c1763a4bf06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be53d6809fd14c1299091d250745d4d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd9fd81e133c4775bb6f66b326ecb6d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
