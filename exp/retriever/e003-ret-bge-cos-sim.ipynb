{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71acc131",
   "metadata": {
    "papermill": {
     "duration": 0.011532,
     "end_time": "2024-09-14T01:45:57.074016",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.062484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 目的\n",
    "bgeでのretrieveファイルの作成\n",
    "\n",
    "- MAP@25: \n",
    "- recall: \n",
    "\n",
    "Please let me know if there are any mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc8a91",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c063a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"e003-ret-bge\"\n",
    "DATA_PATH = \"../../data\"\n",
    "\n",
    "DATA_OUTPUT_PATH = \"../../retrieved_data\"\n",
    "\n",
    "DATASET_NAME = EXP_NAME\n",
    "MODEL_OUTPUT_PATH = f\"../../eedi-mining-misconceptions-in-mathematics/trained_models/retriever/{EXP_NAME}\"\n",
    "\n",
    "RETRIEVE_NUM = 25  # TODO: 多くしてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65096f42",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58124e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==3.1.0 in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (4.42.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (2.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==3.1.0) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers==3.1.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==3.1.0) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers==3.1.0) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers==3.1.0) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers==3.1.0) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==3.1.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.1.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers==3.1.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers==3.1.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers==3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e26266",
   "metadata": {
    "papermill": {
     "duration": 0.010544,
     "end_time": "2024-09-14T01:45:57.095623",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.085079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c0dbcc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-14T01:45:57.119081Z",
     "iopub.status.busy": "2024-09-14T01:45:57.118643Z",
     "iopub.status.idle": "2024-09-14T01:45:59.534275Z",
     "shell.execute_reply": "2024-09-14T01:45:59.532994Z"
    },
    "papermill": {
     "duration": 2.430721,
     "end_time": "2024-09-14T01:45:59.537229",
     "exception": false,
     "start_time": "2024-09-14T01:45:57.106508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a4f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "# import sentence_transformers\n",
    "\n",
    "# assert transformers.__version__ == \"4.44.2\"\n",
    "# assert torch.__version__ == \"2.3.1\"\n",
    "# assert sentence_transformers.__version__ == \"3.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98570c57",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3575674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c21264",
   "metadata": {
    "papermill": {
     "duration": 0.010552,
     "end_time": "2024-09-14T01:45:59.679936",
     "exception": false,
     "start_time": "2024-09-14T01:45:59.669384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b785134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:45:59.748361Z",
     "iopub.status.busy": "2024-09-14T01:45:59.747260Z",
     "iopub.status.idle": "2024-09-14T01:45:59.783052Z",
     "shell.execute_reply": "2024-09-14T01:45:59.781736Z"
    },
    "papermill": {
     "duration": 0.051291,
     "end_time": "2024-09-14T01:45:59.785946",
     "exception": false,
     "start_time": "2024-09-14T01:45:59.734655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( 3 \\times(2+4)-5 \\)&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;A&quot;</td><td>&quot;0_A&quot;</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerBText&quot;</td><td>&quot;\\( 3 \\times 2+(4-5) \\)&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;B&quot;</td><td>&quot;0_B&quot;</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerCText&quot;</td><td>&quot;\\( 3 \\times(2+4-5) \\)&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;C&quot;</td><td>&quot;0_C&quot;</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td></tr><tr><td>1000</td><td>&quot;Simplify an algebraic fraction…</td><td>&quot;Simplifying Algebraic Fraction…</td><td>&quot;Simplify the following, if pos…</td><td>&quot;B&quot;</td><td>&quot;AnswerAText&quot;</td><td>&quot;\\( t \\)&quot;</td><td>&quot;Simplify an algebraic fraction…</td><td>&quot;A&quot;</td><td>&quot;1000_A&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ QuestionI ┆ Construct ┆ SubjectNa ┆ QuestionT ┆ … ┆ AnswerTex ┆ AllText   ┆ AnswerAlp ┆ Question │\n",
       "│ d         ┆ Name      ┆ me        ┆ ext       ┆   ┆ t         ┆ ---       ┆ habet     ┆ Id_Answe │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ str       ┆ ---       ┆ r        │\n",
       "│ i64       ┆ str       ┆ str       ┆ str       ┆   ┆ str       ┆           ┆ str       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ \\( 3 \\tim ┆ Use the   ┆ A         ┆ 0_A      │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ es(2+4)-5 ┆ order of  ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ \\)        ┆ operation ┆           ┆          │\n",
       "│           ┆ s to…     ┆           ┆ \\]        ┆   ┆           ┆ s to…     ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Where do  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ …         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ \\( 3      ┆ Use the   ┆ B         ┆ 0_B      │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ \\times    ┆ order of  ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ 2+(4-5)   ┆ operation ┆           ┆          │\n",
       "│           ┆ s to…     ┆           ┆ \\]        ┆   ┆ \\)        ┆ s to…     ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Where do  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ …         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ \\( 3 \\tim ┆ Use the   ┆ C         ┆ 0_C      │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ es(2+4-5) ┆ order of  ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ \\)        ┆ operation ┆           ┆          │\n",
       "│           ┆ s to…     ┆           ┆ \\]        ┆   ┆           ┆ s to…     ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Where do  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ …         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 0         ┆ Use the   ┆ BIDMAS    ┆ \\[        ┆ … ┆ Does not  ┆ Use the   ┆ D         ┆ 0_D      │\n",
       "│           ┆ order of  ┆           ┆ 3 \\times  ┆   ┆ need      ┆ order of  ┆           ┆          │\n",
       "│           ┆ operation ┆           ┆ 2+4-5     ┆   ┆ brackets  ┆ operation ┆           ┆          │\n",
       "│           ┆ s to…     ┆           ┆ \\]        ┆   ┆           ┆ s to…     ┆           ┆          │\n",
       "│           ┆           ┆           ┆ Where do  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ …         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1000      ┆ Simplify  ┆ Simplifyi ┆ Simplify  ┆ … ┆ \\( t \\)   ┆ Simplify  ┆ A         ┆ 1000_A   │\n",
       "│           ┆ an        ┆ ng        ┆ the follo ┆   ┆           ┆ an        ┆           ┆          │\n",
       "│           ┆ algebraic ┆ Algebraic ┆ wing, if  ┆   ┆           ┆ algebraic ┆           ┆          │\n",
       "│           ┆ fraction… ┆ Fraction… ┆ pos…      ┆   ┆           ┆ fraction… ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_col = [\n",
    "    \"QuestionId\",\n",
    "    \"ConstructName\",\n",
    "    \"SubjectName\",\n",
    "    \"QuestionText\",\n",
    "    \"CorrectAnswer\",\n",
    "]\n",
    "\n",
    "train_long = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .select(\n",
    "        pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n",
    "    )\n",
    "    .unpivot(\n",
    "        index=common_col,\n",
    "        variable_name=\"AnswerType\",\n",
    "        value_name=\"AnswerText\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col(\"ConstructName\"),\n",
    "                pl.col(\"SubjectName\"),\n",
    "                pl.col(\"QuestionText\"),\n",
    "                pl.col(\"AnswerText\"),\n",
    "            ],\n",
    "            separator=\" \",\n",
    "        ).alias(\"AllText\"),\n",
    "        pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n",
    "        ).alias(\"QuestionId_Answer\"),\n",
    "    )\n",
    "    .sort(\"QuestionId_Answer\")\n",
    ")\n",
    "train_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff8dcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId_Answer</th><th>MisconceptionId</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;0_A&quot;</td><td>null</td></tr><tr><td>&quot;0_B&quot;</td><td>null</td></tr><tr><td>&quot;0_C&quot;</td><td>null</td></tr><tr><td>&quot;0_D&quot;</td><td>1672</td></tr><tr><td>&quot;1000_A&quot;</td><td>891</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────────────┬─────────────────┐\n",
       "│ QuestionId_Answer ┆ MisconceptionId │\n",
       "│ ---               ┆ ---             │\n",
       "│ str               ┆ i64             │\n",
       "╞═══════════════════╪═════════════════╡\n",
       "│ 0_A               ┆ null            │\n",
       "│ 0_B               ┆ null            │\n",
       "│ 0_C               ┆ null            │\n",
       "│ 0_D               ┆ 1672            │\n",
       "│ 1000_A            ┆ 891             │\n",
       "└───────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_misconception_long = (\n",
    "    train.select(\n",
    "        pl.col(\n",
    "            common_col + [f\"Misconception{alpha}Id\" for alpha in [\"A\", \"B\", \"C\", \"D\"]]\n",
    "        )\n",
    "    )\n",
    "    .unpivot(\n",
    "        index=common_col,\n",
    "        variable_name=\"MisconceptionType\",\n",
    "        value_name=\"MisconceptionId\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"MisconceptionType\")\n",
    "        .str.extract(r\"Misconception([A-D])Id$\")\n",
    "        .alias(\"AnswerAlphabet\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n",
    "        ).alias(\"QuestionId_Answer\"),\n",
    "    )\n",
    "    .sort(\"QuestionId_Answer\")\n",
    "    .select(pl.col([\"QuestionId_Answer\", \"MisconceptionId\"]))\n",
    "    .with_columns(pl.col(\"MisconceptionId\").cast(pl.Int64))\n",
    ")\n",
    "train_misconception_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c72715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join MisconceptionId\n",
    "train_long = train_long.join(train_misconception_long, on=\"QuestionId_Answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d11def",
   "metadata": {
    "papermill": {
     "duration": 0.010829,
     "end_time": "2024-09-14T01:46:00.109663",
     "exception": false,
     "start_time": "2024-09-14T01:46:00.098834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92d8541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f39bbd1f18a47409e0c4666ee5df4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b36662f598414894506637078fd839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646245b632044bef90b9dff95bb1185b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f534125f555749a4b256e0b9f52e8199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdbea5285e543b386b47489564982ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daac9dd080147d2aae2b3585d8677fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/298 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 23.12 MiB is free. Process 3729483 has 15.75 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 13.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = SentenceTransformer(\"BAAI/bge-large-zh-v1.5\") # CV: 0.06ぐらい\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\") # CV: 0.1841439184198388\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model = SentenceTransformer(\"all-MiniLM-L6-v2\") # CV: 0.17806659878200218\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvidia/NV-Embed-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# CV:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mmax_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32768\u001b[39m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:333\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 23.12 MiB is free. Process 3729483 has 15.75 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 13.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer(\"BAAI/bge-large-zh-v1.5\") # CV: 0.06ぐらい\n",
    "# model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\") # CV: 0.1841439184198388\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\") # CV: 0.17806659878200218\n",
    "model = SentenceTransformer(\"nvidia/NV-Embed-v2\", trust_remote_code=True)  # CV: OOMのため、試せていない\n",
    "model.max_seq_length = # 32768\n",
    "model.tokenizer.padding_side = \"right\"\n",
    "\n",
    "train_long_vec = model.encode(\n",
    "    train_long[\"AllText\"].to_list(), normalize_embeddings=True\n",
    ")\n",
    "misconception_mapping_vec = model.encode(\n",
    "    misconception_mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True\n",
    ")\n",
    "print(train_long_vec.shape)\n",
    "print(misconception_mapping_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6368fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misconception_mapping_vecを保存する\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "np.save(f\"{MODEL_OUTPUT_PATH}/misconception_mapping_vec.npy\", misconception_mapping_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8171be61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:01.415427Z",
     "iopub.status.busy": "2024-09-14T01:46:01.414946Z",
     "iopub.status.idle": "2024-09-14T01:46:06.419565Z",
     "shell.execute_reply": "2024-09-14T01:46:06.418520Z"
    },
    "papermill": {
     "duration": 5.023799,
     "end_time": "2024-09-14T01:46:06.422421",
     "exception": false,
     "start_time": "2024-09-14T01:46:01.398622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cos_sim_arr = cosine_similarity(train_long_vec, misconception_mapping_vec)\n",
    "train_sorted_indices = np.argsort(-train_cos_sim_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3288a590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.485692Z",
     "iopub.status.busy": "2024-09-14T01:46:06.484542Z",
     "iopub.status.idle": "2024-09-14T01:46:06.493692Z",
     "shell.execute_reply": "2024-09-14T01:46:06.492283Z"
    },
    "papermill": {
     "duration": 0.025202,
     "end_time": "2024-09-14T01:46:06.496371",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.471169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example\n",
    "def print_example(df: pl.DataFrame, sorted_indices: np.ndarray, idx: int) -> None:\n",
    "    print(f\"Query idx{idx}\")\n",
    "    print(df[\"AllText\"][idx])\n",
    "    print(\"\\nCos Sim No.1\")\n",
    "    print(misconception_mapping[\"MisconceptionName\"][int(sorted_indices[idx, 0])])\n",
    "    print(\"\\nCos Sim No.2\")\n",
    "    print(misconception_mapping[\"MisconceptionName\"][int(sorted_indices[idx, 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b85607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query idx0\n",
      "Use the order of operations to carry out calculations involving powers BIDMAS \\[\n",
      "3 \\times 2+4-5\n",
      "\\]\n",
      "Where do the brackets need to go to make the answer equal \\( 13 \\) ? \\( 3 \\times(2+4)-5 \\)\n",
      "\n",
      "Cos Sim No.1\n",
      "Applies BIDMAS in strict order (does not realize addition and subtraction, and multiplication and division, are of equal priority)\n",
      "\n",
      "Cos Sim No.2\n",
      "Misunderstands order of operations in algebraic expressions\n"
     ]
    }
   ],
   "source": [
    "print_example(train_long, train_sorted_indices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1211ff44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.521580Z",
     "iopub.status.busy": "2024-09-14T01:46:06.521011Z",
     "iopub.status.idle": "2024-09-14T01:46:06.527584Z",
     "shell.execute_reply": "2024-09-14T01:46:06.526276Z"
    },
    "papermill": {
     "duration": 0.022384,
     "end_time": "2024-09-14T01:46:06.530441",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.508057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query idx1\n",
      "Use the order of operations to carry out calculations involving powers BIDMAS \\[\n",
      "3 \\times 2+4-5\n",
      "\\]\n",
      "Where do the brackets need to go to make the answer equal \\( 13 \\) ? \\( 3 \\times 2+(4-5) \\)\n",
      "\n",
      "Cos Sim No.1\n",
      "Applies BIDMAS in strict order (does not realize addition and subtraction, and multiplication and division, are of equal priority)\n",
      "\n",
      "Cos Sim No.2\n",
      "Misunderstands order of operations in algebraic expressions\n"
     ]
    }
   ],
   "source": [
    "print_example(train_long, train_sorted_indices, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe1e2c",
   "metadata": {
    "papermill": {
     "duration": 0.011086,
     "end_time": "2024-09-14T01:46:06.552908",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.541822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "37b5f922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.579007Z",
     "iopub.status.busy": "2024-09-14T01:46:06.578594Z",
     "iopub.status.idle": "2024-09-14T01:46:06.602802Z",
     "shell.execute_reply": "2024-09-14T01:46:06.601417Z"
    },
    "papermill": {
     "duration": 0.04065,
     "end_time": "2024-09-14T01:46:06.605893",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.565243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_long = train_long.with_columns(\n",
    "    pl.Series(train_sorted_indices[:, :RETRIEVE_NUM].tolist()).alias(\n",
    "        \"PredictMisconceptionId\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19b400a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.631229Z",
     "iopub.status.busy": "2024-09-14T01:46:06.630809Z",
     "iopub.status.idle": "2024-09-14T01:46:06.638133Z",
     "shell.execute_reply": "2024-09-14T01:46:06.636961Z"
    },
    "papermill": {
     "duration": 0.023321,
     "end_time": "2024-09-14T01:46:06.640719",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.617398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1#MAP@3-Metric\n",
    "def map_at_25(predictions, labels):\n",
    "    map_sum = 0\n",
    "    for x, y in zip(predictions, labels):\n",
    "        z = [1 / i if y == j else 0 for i, j in zip(range(1, 26), x)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dbd99f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.666065Z",
     "iopub.status.busy": "2024-09-14T01:46:06.665606Z",
     "iopub.status.idle": "2024-09-14T01:46:06.762803Z",
     "shell.execute_reply": "2024-09-14T01:46:06.761446Z"
    },
    "papermill": {
     "duration": 0.113621,
     "end_time": "2024-09-14T01:46:06.765721",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.652100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1841439184198388"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_25_score = map_at_25(\n",
    "    train_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\n",
    "        \"PredictMisconceptionId\"\n",
    "    ],\n",
    "    train_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\"MisconceptionId\"],\n",
    ")\n",
    "map_at_25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a66afa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T01:46:06.790904Z",
     "iopub.status.busy": "2024-09-14T01:46:06.790453Z",
     "iopub.status.idle": "2024-09-14T01:46:06.809203Z",
     "shell.execute_reply": "2024-09-14T01:46:06.807875Z"
    },
    "papermill": {
     "duration": 0.034606,
     "end_time": "2024-09-14T01:46:06.812192",
     "exception": false,
     "start_time": "2024-09-14T01:46:06.777586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5581235697940503"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(predictions, labels):\n",
    "    acc_num = np.sum([1 for x, y in zip(predictions, labels) if y in x])\n",
    "    return acc_num / len(predictions)\n",
    "\n",
    "\n",
    "recall_score = recall(\n",
    "    train_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\n",
    "        \"PredictMisconceptionId\"\n",
    "    ],\n",
    "    train_long.filter(pl.col(\"MisconceptionId\").is_not_null())[\"MisconceptionId\"],\n",
    ")\n",
    "recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657bf3d",
   "metadata": {
    "papermill": {
     "duration": 0.011875,
     "end_time": "2024-09-14T01:46:07.146569",
     "exception": false,
     "start_time": "2024-09-14T01:46:07.134694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Retrieved Train File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "297ca4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>QuestionId</th><th>ConstructName</th><th>SubjectName</th><th>QuestionText</th><th>CorrectAnswer</th><th>AnswerType</th><th>AnswerText</th><th>AllText</th><th>AnswerAlphabet</th><th>QuestionId_Answer</th><th>MisconceptionId</th><th>PredictMisconceptionId</th><th>target</th><th>MisconceptionId_right</th><th>MisconceptionName</th><th>PredictMisconceptionName</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2306</td><td>0</td><td>2306</td><td>&quot;Applies BIDMAS in strict order…</td><td>&quot;Applies BIDMAS in strict order…</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2586</td><td>0</td><td>2586</td><td>&quot;Misunderstands order of operat…</td><td>&quot;Misunderstands order of operat…</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2488</td><td>0</td><td>2488</td><td>&quot;Answers order of operations qu…</td><td>&quot;Answers order of operations qu…</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>2518</td><td>0</td><td>2518</td><td>&quot;May have made a calculation er…</td><td>&quot;May have made a calculation er…</td></tr><tr><td>0</td><td>&quot;Use the order of operations to…</td><td>&quot;BIDMAS&quot;</td><td>&quot;\\[\n",
       "3 \\times 2+4-5\n",
       "\\]\n",
       "Where do …</td><td>&quot;A&quot;</td><td>&quot;AnswerDText&quot;</td><td>&quot;Does not need brackets&quot;</td><td>&quot;Use the order of operations to…</td><td>&quot;D&quot;</td><td>&quot;0_D&quot;</td><td>1672</td><td>1316</td><td>0</td><td>1316</td><td>&quot;Does not understand that the n…</td><td>&quot;Does not understand that the n…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌────────────┬────────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────────┐\n",
       "│ QuestionId ┆ ConstructN ┆ SubjectNa ┆ QuestionT ┆ … ┆ target ┆ Misconcep ┆ Misconcep ┆ PredictMi │\n",
       "│ ---        ┆ ame        ┆ me        ┆ ext       ┆   ┆ ---    ┆ tionId_ri ┆ tionName  ┆ sconcepti │\n",
       "│ i64        ┆ ---        ┆ ---       ┆ ---       ┆   ┆ i64    ┆ ght       ┆ ---       ┆ onName    │\n",
       "│            ┆ str        ┆ str       ┆ str       ┆   ┆        ┆ ---       ┆ str       ┆ ---       │\n",
       "│            ┆            ┆           ┆           ┆   ┆        ┆ i64       ┆           ┆ str       │\n",
       "╞════════════╪════════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0          ┆ Use the    ┆ BIDMAS    ┆ \\[        ┆ … ┆ 0      ┆ 2306      ┆ Applies   ┆ Applies   │\n",
       "│            ┆ order of   ┆           ┆ 3 \\times  ┆   ┆        ┆           ┆ BIDMAS in ┆ BIDMAS in │\n",
       "│            ┆ operations ┆           ┆ 2+4-5     ┆   ┆        ┆           ┆ strict    ┆ strict    │\n",
       "│            ┆ to…        ┆           ┆ \\]        ┆   ┆        ┆           ┆ order…    ┆ order…    │\n",
       "│            ┆            ┆           ┆ Where do  ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆           ┆ …         ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 0          ┆ Use the    ┆ BIDMAS    ┆ \\[        ┆ … ┆ 0      ┆ 2586      ┆ Misunders ┆ Misunders │\n",
       "│            ┆ order of   ┆           ┆ 3 \\times  ┆   ┆        ┆           ┆ tands     ┆ tands     │\n",
       "│            ┆ operations ┆           ┆ 2+4-5     ┆   ┆        ┆           ┆ order of  ┆ order of  │\n",
       "│            ┆ to…        ┆           ┆ \\]        ┆   ┆        ┆           ┆ operat…   ┆ operat…   │\n",
       "│            ┆            ┆           ┆ Where do  ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆           ┆ …         ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 0          ┆ Use the    ┆ BIDMAS    ┆ \\[        ┆ … ┆ 0      ┆ 2488      ┆ Answers   ┆ Answers   │\n",
       "│            ┆ order of   ┆           ┆ 3 \\times  ┆   ┆        ┆           ┆ order of  ┆ order of  │\n",
       "│            ┆ operations ┆           ┆ 2+4-5     ┆   ┆        ┆           ┆ operation ┆ operation │\n",
       "│            ┆ to…        ┆           ┆ \\]        ┆   ┆        ┆           ┆ s qu…     ┆ s qu…     │\n",
       "│            ┆            ┆           ┆ Where do  ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆           ┆ …         ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 0          ┆ Use the    ┆ BIDMAS    ┆ \\[        ┆ … ┆ 0      ┆ 2518      ┆ May have  ┆ May have  │\n",
       "│            ┆ order of   ┆           ┆ 3 \\times  ┆   ┆        ┆           ┆ made a    ┆ made a    │\n",
       "│            ┆ operations ┆           ┆ 2+4-5     ┆   ┆        ┆           ┆ calculati ┆ calculati │\n",
       "│            ┆ to…        ┆           ┆ \\]        ┆   ┆        ┆           ┆ on er…    ┆ on er…    │\n",
       "│            ┆            ┆           ┆ Where do  ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆           ┆ …         ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 0          ┆ Use the    ┆ BIDMAS    ┆ \\[        ┆ … ┆ 0      ┆ 1316      ┆ Does not  ┆ Does not  │\n",
       "│            ┆ order of   ┆           ┆ 3 \\times  ┆   ┆        ┆           ┆ understan ┆ understan │\n",
       "│            ┆ operations ┆           ┆ 2+4-5     ┆   ┆        ┆           ┆ d that    ┆ d that    │\n",
       "│            ┆ to…        ┆           ┆ \\]        ┆   ┆        ┆           ┆ the n…    ┆ the n…    │\n",
       "│            ┆            ┆           ┆ Where do  ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆           ┆ …         ┆   ┆        ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_retrieved = (\n",
    "    train_long.filter(\n",
    "        pl.col(\n",
    "            \"MisconceptionId\"\n",
    "        ).is_not_null()  # TODO: Consider ways to utilize data where MisconceptionId is NaN.\n",
    "    )\n",
    "    .explode(\"PredictMisconceptionId\")\n",
    "    .with_columns(\n",
    "        (pl.col(\"MisconceptionId\") == pl.col(\"PredictMisconceptionId\"))\n",
    "        .cast(pl.Int64)\n",
    "        .alias(\"target\")\n",
    "    )\n",
    "    .join(\n",
    "        misconception_mapping.with_columns(pl.all().name.prefix(\"Predict\")),\n",
    "        on=\"PredictMisconceptionId\",\n",
    "    )\n",
    ")\n",
    "train_retrieved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5fdd7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_retrieved.write_csv(\n",
    "    f\"{DATA_OUTPUT_PATH}/e001-train_ret{RETRIEVE_NUM}_map{map_at_25_score:.4f}_recall{recall_score:.4f}.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{DATA_OUTPUT_PATH}/e001-train_ret{RETRIEVE_NUM}_map{map_at_25_score:.4f}_recall{recall_score:.4f}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa7596",
   "metadata": {},
   "source": [
    "# Kaggle Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "    # if \"_\" in dataset_name:\n",
    "    #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "    dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "    dataset_metadata[\"title\"] = dataset_name\n",
    "    with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "\n",
    "print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f1c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9551816,
     "sourceId": 82695,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.614286,
   "end_time": "2024-09-14T01:46:08.075104",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-14T01:45:53.460818",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
